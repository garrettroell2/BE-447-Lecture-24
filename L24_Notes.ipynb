{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7228f48",
   "metadata": {},
   "source": [
    "# Name Generative AI 2\n",
    "\n",
    "Steps:\n",
    "1. Set up the imports\n",
    "2. Read the names from the file\n",
    "3. Create the vocab\n",
    "4. Create the training data (previous n letters -> next letter)\n",
    "5. Train multiple neural networks (multilayer perceptron in scikit learn)\n",
    "6. Generate ~20 test names using a function\n",
    "\n",
    "n = context length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1095b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up imports\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40915b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the names file\n",
    "with open('names.txt') as file:\n",
    "    names = file.read().splitlines()\n",
    "\n",
    "# only use the first 3000 names\n",
    "names = names[:3000]\n",
    "\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a088568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the 'vocabulary'\n",
    "all_names = ' '.join(names)\n",
    "\n",
    "# create a sorted list of the unique characters in names\n",
    "vocab = sorted(list(set(all_names)))\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e52fe5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build mappings between characters and integers\n",
    "char_to_int = {ch: i for i, ch in enumerate(vocab)}\n",
    "int_to_char = {i: ch for i, ch in enumerate(vocab)}\n",
    "\n",
    "int_to_char[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91e06fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21120"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training data\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "context_length = 5\n",
    "\n",
    "# loop over the names\n",
    "for name in names:\n",
    "    # add the start and end space characters\n",
    "    name = ' ' * context_length + name + ' '\n",
    "\n",
    "    # loop over the letters in the name and the end character\n",
    "    for index in range(len(name) - context_length):\n",
    "\n",
    "        # get the context string and target letter\n",
    "        context = name[index:index + context_length]\n",
    "        target = name[index + context_length]\n",
    "\n",
    "        # convert to integers\n",
    "        context_ints = [char_to_int[char] for char in context]\n",
    "        target_int = char_to_int[target]\n",
    "\n",
    "        # add to X and y lists\n",
    "        X.append(context_ints)\n",
    "        y.append(target_int)\n",
    "\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2dd2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(1.7885026901662904)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define our neural network model\n",
    "clf = MLPClassifier(random_state=42, hidden_layer_sizes=(100, 100, 100))\n",
    "\n",
    "# train the model\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c074c4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.54672957e-04, 1.57469975e-01, 3.13318722e-02, 4.30315395e-02,\n",
       "       3.28491099e-02, 4.94180791e-02, 1.21777533e-02, 1.93462816e-02,\n",
       "       3.51755999e-02, 2.41346066e-02, 6.96916951e-02, 9.40381794e-02,\n",
       "       6.77588783e-02, 9.72438580e-02, 2.57345043e-02, 6.27862537e-03,\n",
       "       1.97133231e-02, 1.26456379e-03, 5.61171576e-02, 7.81258904e-02,\n",
       "       2.45086442e-02, 1.00871389e-03, 1.29730096e-02, 7.50395380e-03,\n",
       "       2.67407015e-03, 1.03884745e-02, 1.98869689e-02])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the probability distribution for the first letter\n",
    "test_context = [0] * context_length\n",
    "\n",
    "clf.predict_proba([test_context])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4869baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oooa \n",
      "hayna \n",
      "gsala \n",
      "heatia \n",
      "jomdy \n",
      "iarleen \n",
      "fry \n",
      "addeyana \n",
      "hvll \n",
      "ziae \n",
      "kara \n",
      "ayatia \n",
      "kazlynn \n",
      "mille \n",
      "lailyn \n",
      "kayiyah \n",
      "nyeyn \n",
      "elmersier \n",
      "alisah \n",
      "poxabelanea \n"
     ]
    }
   ],
   "source": [
    "# function to generate a name\n",
    "def generate_name():\n",
    "    # create an empty string for the name\n",
    "    name = ''\n",
    "\n",
    "    # define inital values for first and next characters\n",
    "    context = ' ' * context_length\n",
    "    next_char = ''\n",
    "\n",
    "    # loop and add letters until the end character is reached\n",
    "    while next_char != ' ':\n",
    "        # convert the context to integers\n",
    "        context_ints = [char_to_int[char] for char in context]\n",
    "\n",
    "        # generate the probabilities of next character\n",
    "        probs = clf.predict_proba([context_ints])[0]\n",
    "\n",
    "        # select the next letter using weighted probabilities\n",
    "        next_char_int = np.random.choice(range(len(vocab)), p=probs)\n",
    "\n",
    "        # get the character from the int\n",
    "        next_char = int_to_char[next_char_int]\n",
    "\n",
    "        # add letter to name\n",
    "        name += next_char\n",
    "\n",
    "        # update the context\n",
    "        context = context[1:] + next_char\n",
    "\n",
    "    # return the name\n",
    "    return name \n",
    "\n",
    "for _ in range(20):\n",
    "    print(generate_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc58b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
